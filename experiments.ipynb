{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7933d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jives\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d16cd66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationCollector:\n",
    "    def __init__(self, model, layer_idx, device='cuda'):\n",
    "        self.model = model\n",
    "        self.layer_idx = layer_idx\n",
    "        self.device = device\n",
    "        self.handles = []\n",
    "        self.buffer = None\n",
    "\n",
    "    def _hook(self, module, input, output):\n",
    "        # output is typically (hidden_states,) or a tensor depending model\n",
    "        # adapt depending on model internals; here assume output is tensor [batch, seq, dim]\n",
    "        # we store a copy on CPU for safety\n",
    "        self.buffer = output.detach().cpu()\n",
    "\n",
    "    def register(self):\n",
    "        # For HF GPT-like models the transformer blocks are often model.transformer.h or model.base_model.h\n",
    "        # adapt this to your model. Example for gpt2: model.transformer.h[layer_idx].mlp or .ln_ etc.\n",
    "        block = None\n",
    "        # try a couple standard locations:\n",
    "        if hasattr(self.model, 'transformer') and hasattr(self.model.transformer, 'h'):\n",
    "            block = self.model.transformer.h[self.layer_idx]\n",
    "        elif hasattr(self.model, 'base_model') and hasattr(self.model.base_model, 'h'):\n",
    "            block = self.model.base_model.h[self.layer_idx]\n",
    "        else:\n",
    "            raise RuntimeError(\"Adapt which module to hook for your model\")\n",
    "\n",
    "        # hook the block's output (choose e.g. after the MLP or after attention). Use block.mlp or block.ln_... adjust as needed\n",
    "        handle = block.register_forward_hook(self._hook)\n",
    "        self.handles.append(handle)\n",
    "\n",
    "    def remove(self):\n",
    "        for h in self.handles:\n",
    "            h.remove()\n",
    "        self.handles = []\n",
    "\n",
    "    def collect_for_prompts(self, prompts, tokenizer, device='cuda', batch_size=4, token_index=-1):\n",
    "        device = self.device\n",
    "        results = []\n",
    "        self.register()\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        dl = DataLoader(prompts, batch_size=batch_size)\n",
    "        for batch in dl:\n",
    "            enc = tokenizer(batch, return_tensors='pt', padding=True).to(device)\n",
    "            with torch.no_grad():\n",
    "                _ = self.model(**enc)\n",
    "                # buffer shape: [batch, seq_len, dim]\n",
    "                buf = self.buffer  # on CPU\n",
    "                # choose token index (e.g., final token)\n",
    "                if token_index == -1:\n",
    "                    activs = buf[:, (enc['input_ids'] != tokenizer.pad_token_id).sum(dim=1)-1, :].numpy()\n",
    "                else:\n",
    "                    activs = buf[:, token_index, :].numpy()\n",
    "                results.append(activs)\n",
    "        self.remove()\n",
    "        return np.concatenate(results, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda00e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"gpt2\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# collector = ActivationCollector(model, layer_idx=6, device=device)\n",
    "# # prompts_target = [\"How to build a harmful device ...\", ...]   # your forget prompts\n",
    "# # prompts_non = [\"What is the capital of France?\", ...]\n",
    "# # acts_target = collector.collect_for_prompts(prompts_target, tokenizer, batch_size=8)\n",
    "# # acts_non = collector.collect_for_prompts(prompts_non, tokenizer, batch_size=8)\n",
    "# # # acts_target: shape [N_target, hidden_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of \"Don't Forget It! Conditional Sparse Autoencoder Clamping Works for Unlearning\"\n",
    "\n",
    "This implementation provides the core methodology for using Sparse Autoencoders (SAEs)\n",
    "to identify and suppress harmful knowledge in LLMs while retaining benign capabilities.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UnlearningConfig:\n",
    "    \"\"\"Configuration for the unlearning process\"\"\"\n",
    "    activation_threshold: float = 0.01  # Threshold for considering a latent \"active\"\n",
    "    clamp_coefficient: float = -5.0  # Negative coefficient for clamping harmful features\n",
    "    refusal_coefficient: float = 3.0  # Positive coefficient for refusal feature\n",
    "    layer_indices: List[int] = field(default_factory = list)  # Which layers to apply SAE intervention\n",
    "    \n",
    "\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Sparse Autoencoder for interpreting model activations.\n",
    "    \n",
    "    Architecture:\n",
    "        - Encoder: Linear layer with ReLU activation\n",
    "        - Decoder: Linear layer to reconstruct original activations\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, d_sae: int, l1_coefficient: float = 1e-4,device: Optional[torch.device] = None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_sae = d_sae\n",
    "        self.l1_coefficient = l1_coefficient\n",
    "        self.device = device or torch.device(\"cpu\")\n",
    "        \n",
    "        # Encoder: maps activations to sparse latent space\n",
    "        self.encoder = nn.Linear(d_model, d_sae)\n",
    "        self.encoder_bias = nn.Parameter(torch.zeros(d_sae))\n",
    "        \n",
    "        # Decoder: reconstructs activations from latents\n",
    "        self.decoder = nn.Linear(d_sae, d_model, bias=False)\n",
    "        \n",
    "        # Pre-encoder bias to center the data\n",
    "        self.pre_bias = nn.Parameter(torch.zeros(d_model))\n",
    "        \n",
    "        self._init_weights()\n",
    "        self.to(self.device)\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights for better training\"\"\"\n",
    "        nn.init.kaiming_uniform_(self.encoder.weight)\n",
    "        nn.init.kaiming_uniform_(self.decoder.weight)\n",
    "        \n",
    "        # Normalize decoder columns to unit norm\n",
    "        with torch.no_grad():\n",
    "            self.decoder.weight.data = F.normalize(self.decoder.weight.data, dim=1)\n",
    "    \n",
    "    def _flatten_if_needed(self, x: torch.Tensor) -> Tuple[torch.Tensor, Optional[Tuple[int,int]]]:\n",
    "        \"\"\"\n",
    "        If input is [B, S, D], flatten to [B*S, D] and return shape info.\n",
    "        If input is [B, D], return it and None.\n",
    "        \"\"\"\n",
    "        if x.dim() == 3:\n",
    "            B, S, D = x.shape\n",
    "            x_flat = x.reshape(B * S, D)\n",
    "            return x_flat, (B, S)\n",
    "        elif x.dim() == 2:\n",
    "            return x, None\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected input dim={x.dim()}, expected 2 or 3\")\n",
    "    \n",
    "    def _unflatten(self, x_flat: torch.Tensor, shape_info: Optional[Tuple[int,int]]) -> torch.Tensor:\n",
    "        if shape_info is None:\n",
    "            return x_flat\n",
    "        B, S = shape_info\n",
    "        return x_flat.reshape(B, S, -1)\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Encode activations to sparse latent space\"\"\"\n",
    "        x_centered = x - self.pre_bias\n",
    "        latents = F.relu(self.encoder(x_centered) + self.encoder_bias)\n",
    "        return latents\n",
    "    \n",
    "    def decode(self, latents: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Decode latents back to activation space\"\"\"\n",
    "        return self.decoder(latents) + self.pre_bias\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Forward pass with reconstruction\"\"\"\n",
    "        latents = self.encode(x)\n",
    "        reconstruction = self.decode(latents)\n",
    "        return reconstruction, latents\n",
    "    \n",
    "    def loss(self, x: torch.Tensor, reconstruction: torch.Tensor, \n",
    "             latents: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute SAE loss with L1 sparsity penalty\"\"\"\n",
    "        mse_loss = F.mse_loss(reconstruction, x)\n",
    "        l1_loss = self.l1_coefficient * torch.abs(latents).sum(dim=-1).mean()\n",
    "        return mse_loss + l1_loss\n",
    "\n",
    "\n",
    "class FeatureIdentifier:\n",
    "    \"\"\"\n",
    "    Identifies harmful and refusal features in SAE latent space.\n",
    "    \n",
    "    This class analyzes activation patterns on forget vs retain datasets\n",
    "    to identify features associated with harmful knowledge.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_activation_frequency(\n",
    "        latents: torch.Tensor, \n",
    "        threshold: float = 0.01\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute frequency of non-zero activations for each feature.\n",
    "        \n",
    "        Args:\n",
    "            latents: [batch, seq_len, d_sae] SAE latent activations\n",
    "            threshold: minimum value to consider a latent \"active\"\n",
    "        \n",
    "        Returns:\n",
    "            frequencies: [d_sae] proportion of times each feature is active\n",
    "        \"\"\"\n",
    "        if latents.dim() == 2:\n",
    "            # [N, d_sae]\n",
    "            active = (latents.abs() > threshold).float()\n",
    "            freqs = active.mean(dim=0)\n",
    "            return freqs\n",
    "        elif latents.dim() == 3:\n",
    "            # [B, S, d_sae]\n",
    "            active = (latents.abs() > threshold).float()\n",
    "            freqs = active.mean(dim=(0, 1))\n",
    "            return freqs\n",
    "        else:\n",
    "            raise ValueError(\"latents must be 2D or 3D\")\n",
    "        \n",
    "#         active = (latents.abs() > threshold).float()\n",
    "#         frequencies = active.mean(dim=[0, 1])\n",
    "#         return frequencies\n",
    "    \n",
    "    @staticmethod\n",
    "    def identify_harmful_features(\n",
    "        forget_latents: torch.Tensor,\n",
    "        retain_latents: torch.Tensor,\n",
    "        threshold: float = 0.01,\n",
    "        min_frequency_ratio: float = 2.0\n",
    "    ) -> List[int]:\n",
    "        \"\"\"\n",
    "        Identify features more active on forget data than retain data.\n",
    "        \n",
    "        Args:\n",
    "            forget_latents: Activations on harmful/forget dataset\n",
    "            retain_latents: Activations on benign/retain dataset\n",
    "            threshold: activation threshold\n",
    "            min_frequency_ratio: minimum ratio of forget/retain frequency\n",
    "        \n",
    "        Returns:\n",
    "            List of feature indices to clamp\n",
    "        \"\"\"\n",
    "        forget_freq = FeatureIdentifier.compute_activation_frequency(\n",
    "            forget_latents, threshold\n",
    "        )\n",
    "        retain_freq = FeatureIdentifier.compute_activation_frequency(\n",
    "            retain_latents, threshold\n",
    "        )\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        retain_freq = torch.clamp(retain_freq, min=1e-8)\n",
    "        \n",
    "        # Features that activate much more on forget data\n",
    "        frequency_ratio = forget_freq / retain_freq\n",
    "        harmful_mask = frequency_ratio > min_frequency_ratio\n",
    "        \n",
    "        harmful_indices = torch.where(harmful_mask)[0].tolist()\n",
    "        return harmful_indices\n",
    "    \n",
    "    @staticmethod\n",
    "    def identify_refusal_feature(\n",
    "        refusal_latents: torch.Tensor,\n",
    "        threshold: float = 0.01\n",
    "    ) -> int:\n",
    "        \"\"\"\n",
    "        Identify the primary refusal feature.\n",
    "        \n",
    "        Args:\n",
    "            refusal_latents: Activations when model produces refusal responses\n",
    "            threshold: activation threshold\n",
    "        \n",
    "        Returns:\n",
    "            Index of the most frequently activated refusal feature\n",
    "        \"\"\"\n",
    "        frequencies = FeatureIdentifier.compute_activation_frequency(\n",
    "            refusal_latents, threshold\n",
    "        )\n",
    "        refusal_feature = torch.argmax(frequencies).item()\n",
    "        return refusal_feature\n",
    "\n",
    "\n",
    "class ConditionalClampingIntervenor:\n",
    "    \"\"\"\n",
    "    Implements conditional clamping during inference.\n",
    "    \n",
    "    Two main methods:\n",
    "    1. Clamp Prime: Clamps harmful features to negative values\n",
    "    2. Refusal Clamp: Additionally boosts refusal feature when harmful features active\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        sae: SparseAutoencoder,\n",
    "        harmful_features: List[int],\n",
    "        refusal_feature: Optional[int] = None,\n",
    "        config: UnlearningConfig = None\n",
    "    ):\n",
    "        self.sae = sae\n",
    "        self.harmful_features = harmful_features\n",
    "        self.refusal_feature = refusal_feature\n",
    "        self.config = config or UnlearningConfig()\n",
    "    \n",
    "    def clamp_prime(\n",
    "        self, \n",
    "        activations: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Clamp Prime method: Set harmful features to negative values.\n",
    "        \n",
    "        Args:\n",
    "            activations: Original model activations [batch, seq_len, d_model]\n",
    "        \n",
    "        Returns:\n",
    "            Modified activations with harmful features clamped\n",
    "        \"\"\"\n",
    "        # Encode to SAE latent space\n",
    "        latents = self.sae.encode(activations)\n",
    "        \n",
    "        # Clamp harmful features to negative coefficient\n",
    "        for feat_idx in self.harmful_features:\n",
    "            # Only clamp if feature is active\n",
    "            active_mask = latents[..., feat_idx] > self.config.activation_threshold\n",
    "            latents[..., feat_idx] = torch.where(\n",
    "                active_mask,\n",
    "                torch.full_like(latents[..., feat_idx], self.config.clamp_coefficient),\n",
    "                latents[..., feat_idx]\n",
    "            )\n",
    "        \n",
    "        # Decode back to activation space\n",
    "        modified_activations = self.sae.decode(latents)\n",
    "        return modified_activations\n",
    "    \n",
    "    def refusal_clamp(\n",
    "        self,\n",
    "        activations: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Refusal Clamp method: Clamp harmful features AND boost refusal feature.\n",
    "        \n",
    "        This method is more aggressive - whenever harmful features are detected,\n",
    "        it both suppresses them and activates the refusal mechanism.\n",
    "        \n",
    "        Args:\n",
    "            activations: Original model activations [batch, seq_len, d_model]\n",
    "        \n",
    "        Returns:\n",
    "            Modified activations with clamping and refusal boost\n",
    "        \"\"\"\n",
    "        if self.refusal_feature is None:\n",
    "            raise ValueError(\"Refusal feature must be specified for refusal_clamp\")\n",
    "        \n",
    "        # Encode to SAE latent space\n",
    "        latents = self.sae.encode(activations)\n",
    "        \n",
    "        # Check if any harmful feature is active\n",
    "        harmful_active = torch.zeros(\n",
    "            latents.shape[:-1], \n",
    "            dtype=torch.bool, \n",
    "            device=latents.device\n",
    "        )\n",
    "        \n",
    "        for feat_idx in self.harmful_features:\n",
    "            active = latents[..., feat_idx] > self.config.activation_threshold\n",
    "            harmful_active = harmful_active | active\n",
    "            \n",
    "            # Clamp harmful feature\n",
    "            latents[..., feat_idx] = torch.where(\n",
    "                active,\n",
    "                torch.full_like(latents[..., feat_idx], self.config.clamp_coefficient),\n",
    "                latents[..., feat_idx]\n",
    "            )\n",
    "        \n",
    "        # If harmful features detected, boost refusal feature\n",
    "        latents[..., self.refusal_feature] = torch.where(\n",
    "            harmful_active,\n",
    "            torch.full_like(\n",
    "                latents[..., self.refusal_feature], \n",
    "                self.config.refusal_coefficient\n",
    "            ),\n",
    "            latents[..., self.refusal_feature]\n",
    "        )\n",
    "        \n",
    "        # Decode back to activation space\n",
    "        modified_activations = self.sae.decode(latents)\n",
    "        return modified_activations\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        activations: torch.Tensor,\n",
    "        use_refusal: bool = False\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Apply clamping intervention\"\"\"\n",
    "        if use_refusal:\n",
    "            return self.refusal_clamp(activations)\n",
    "        else:\n",
    "            return self.clamp_prime(activations)\n",
    "\n",
    "\n",
    "class UnlearningPipeline:\n",
    "    \"\"\"\n",
    "    Complete pipeline for SAE-based unlearning.\n",
    "    \n",
    "    Steps:\n",
    "    1. Train SAE on model activations\n",
    "    2. Identify harmful and refusal features\n",
    "    3. Apply conditional clamping during inference\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        layer_indices: List[int],\n",
    "        d_model: int,\n",
    "        d_sae: int = None,\n",
    "        config: UnlearningConfig = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: The LLM to apply unlearning to\n",
    "            layer_indices: Which transformer layers to intervene on\n",
    "            d_model: Hidden dimension of the model\n",
    "            d_sae: SAE latent dimension (typically 4-8x d_model)\n",
    "            config: Unlearning configuration\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.layer_indices = layer_indices\n",
    "        self.d_model = d_model\n",
    "        self.d_sae = d_sae or (d_model * 4)  # Default: 4x expansion\n",
    "        self.config = config or UnlearningConfig()\n",
    "        \n",
    "        # Create SAE for each layer\n",
    "        self.saes = nn.ModuleDict({\n",
    "            str(layer_idx): SparseAutoencoder(d_model, self.d_sae)\n",
    "            for layer_idx in layer_indices\n",
    "        })\n",
    "        \n",
    "        self.interventors = {}\n",
    "        self.hooks = []\n",
    "    \n",
    "    def train_sae(\n",
    "        self,\n",
    "        layer_idx: int,\n",
    "        activations: torch.Tensor,\n",
    "        num_epochs: int = 100,\n",
    "        batch_size: int = 256,\n",
    "        lr: float = 1e-3\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Train SAE on collected activations.\n",
    "        \n",
    "        Args:\n",
    "            layer_idx: Which layer's SAE to train\n",
    "            activations: Collected activations [num_samples, d_model]\n",
    "            num_epochs: Training epochs\n",
    "            batch_size: Batch size\n",
    "            lr: Learning rate\n",
    "        \"\"\"\n",
    "        sae = self.saes[str(layer_idx)]\n",
    "        optimizer = torch.optim.Adam(sae.parameters(), lr=lr)\n",
    "        \n",
    "        # Flatten for training to [N_total, D]\n",
    "        if activations.dim() == 3:\n",
    "            N, S, D = activations.shape\n",
    "            activations = activations.reshape(N * S, D)\n",
    "        elif activations.dim() == 2:\n",
    "            activations = activations\n",
    "        else:\n",
    "            raise ValueError(\"activations must be 2D or 3D\")\n",
    "        \n",
    "        dataset = torch.utils.data.TensorDataset(activations)\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        sae.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0\n",
    "            for batch in dataloader:\n",
    "                x = batch[0]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                reconstruction, latents = sae(x)\n",
    "                loss = sae.loss(x, reconstruction, latents)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                avg_loss = total_loss / len(dataloader)\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        sae.eval()\n",
    "    \n",
    "    def identify_features(\n",
    "        self,\n",
    "        layer_idx: int,\n",
    "        forget_data: torch.Tensor,\n",
    "        retain_data: torch.Tensor,\n",
    "        refusal_data: Optional[torch.Tensor] = None\n",
    "    ) -> Tuple[List[int], Optional[int]]:\n",
    "        \"\"\"\n",
    "        Identify harmful and refusal features for a layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_idx: Which layer to analyze\n",
    "            forget_data: Activations on harmful/forget dataset\n",
    "            retain_data: Activations on benign/retain dataset  \n",
    "            refusal_data: Activations on refusal responses (optional)\n",
    "        \n",
    "        Returns:\n",
    "            (harmful_features, refusal_feature)\n",
    "        \"\"\"\n",
    "        sae = self.saes[str(layer_idx)]\n",
    "        sae.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get latent activations\n",
    "            forget_latents = sae.encode(forget_data).unsqueeze(1)\n",
    "            retain_latents = sae.encode(retain_data).unsqueeze(1)\n",
    "            \n",
    "            # Identify harmful features\n",
    "            harmful_features = FeatureIdentifier.identify_harmful_features(\n",
    "                forget_latents,\n",
    "                retain_latents,\n",
    "                threshold=self.config.activation_threshold\n",
    "            )\n",
    "            \n",
    "            # Identify refusal feature if data provided\n",
    "            refusal_feature = None\n",
    "            if refusal_data is not None:\n",
    "                refusal_latents = sae.encode(refusal_data).unsqueeze(1)\n",
    "                refusal_feature = FeatureIdentifier.identify_refusal_feature(\n",
    "                    refusal_latents,\n",
    "                    threshold=self.config.activation_threshold\n",
    "                )\n",
    "        \n",
    "        return harmful_features, refusal_feature\n",
    "    \n",
    "    def setup_interventions(\n",
    "        self,\n",
    "        layer_idx: int,\n",
    "        harmful_features: List[int],\n",
    "        refusal_feature: Optional[int] = None\n",
    "    ):\n",
    "        \"\"\"Setup interventor for a specific layer\"\"\"\n",
    "        sae = self.saes[str(layer_idx)]\n",
    "        interventor = ConditionalClampingIntervenor(\n",
    "            sae=sae,\n",
    "            harmful_features=harmful_features,\n",
    "            refusal_feature=refusal_feature,\n",
    "            config=self.config\n",
    "        )\n",
    "        self.interventors[layer_idx] = interventor\n",
    "    \n",
    "    def apply_hooks(self, use_refusal: bool = False):\n",
    "        \"\"\"\n",
    "        Apply forward hooks to intervene on model activations during inference.\n",
    "        \n",
    "        Args:\n",
    "            use_refusal: Whether to use refusal clamping (more aggressive)\n",
    "        \"\"\"\n",
    "        self.remove_hooks()\n",
    "        \n",
    "        for layer_idx in self.layer_indices:\n",
    "            if layer_idx not in self.interventors:\n",
    "                continue\n",
    "            \n",
    "            interventor = self.interventors[layer_idx]\n",
    "            \n",
    "            def hook_fn(module, input, output, interventor=interventor, use_refusal=use_refusal):\n",
    "                # Assuming output is the activation tensor\n",
    "                if isinstance(output, tuple):\n",
    "                    activations = output[0]\n",
    "                else:\n",
    "                    activations = output\n",
    "                \n",
    "                # Apply intervention\n",
    "                modified = interventor(activations, use_refusal=use_refusal)\n",
    "                \n",
    "                if isinstance(output, tuple):\n",
    "                    return (modified,) + output[1:]\n",
    "                else:\n",
    "                    return modified\n",
    "            \n",
    "            # Register hook (exact layer access depends on model architecture)\n",
    "            # This is a placeholder - adapt to your specific model\n",
    "            layer = self._get_layer(layer_idx)\n",
    "            handle = layer.register_forward_hook(hook_fn)\n",
    "            self.hooks.append(handle)\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        \"\"\"Remove all registered hooks\"\"\"\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks = []\n",
    "    \n",
    "    def _get_layer(self, layer_idx: int):\n",
    "        \"\"\"\n",
    "        Get the transformer layer by index.\n",
    "        This is model-specific and needs to be adapted.\n",
    "        \"\"\"\n",
    "        # Example for common transformer architectures:\n",
    "        # return self.model.transformer.h[layer_idx]  # GPT-2 style\n",
    "        # return self.model.model.layers[layer_idx]   # LLaMA style\n",
    "        if hasattr(self.model, \"transformer\") and hasattr(self.model.transformer, \"h\"):\n",
    "            return self.model.transformer.h[layer_idx]\n",
    "        raise NotImplementedError(\"Implement layer access for your model in _get_layer()\")\n",
    "\n",
    "# Example usage\n",
    "def example_usage():\n",
    "    \"\"\"\n",
    "    Demonstrates how to use the unlearning pipeline.\n",
    "    \"\"\"\n",
    "    # Hyperparameters\n",
    "    d_model = 768\n",
    "    d_sae = 3072  # 4x expansion\n",
    "    layer_indices = [6, 7, 8]  # Middle layers often work best\n",
    "    \n",
    "    # Initialize pipeline (model is a placeholder)\n",
    "    model = None  # Your actual LLM\n",
    "    pipeline = UnlearningPipeline(\n",
    "        model=model,\n",
    "        layer_indices=layer_indices,\n",
    "        d_model=d_model,\n",
    "        d_sae=d_sae\n",
    "    )\n",
    "    \n",
    "    # Step 1: Collect activations (you need to implement activation collection)\n",
    "    # forget_activations = collect_activations(model, forget_dataset, layer_indices)\n",
    "    # retain_activations = collect_activations(model, retain_dataset, layer_indices)\n",
    "    # refusal_activations = collect_activations(model, refusal_dataset, layer_indices)\n",
    "    \n",
    "    # Step 2: Train SAEs for each layer\n",
    "    for layer_idx in layer_indices:\n",
    "        print(f\"Training SAE for layer {layer_idx}\")\n",
    "        # activations = all_activations[layer_idx]\n",
    "        # pipeline.train_sae(layer_idx, activations)\n",
    "    \n",
    "    # Step 3: Identify features\n",
    "    for layer_idx in layer_indices:\n",
    "        print(f\"Identifying features for layer {layer_idx}\")\n",
    "        # harmful, refusal = pipeline.identify_features(\n",
    "        #     layer_idx,\n",
    "        #     forget_activations[layer_idx],\n",
    "        #     retain_activations[layer_idx],\n",
    "        #     refusal_activations[layer_idx]\n",
    "        # )\n",
    "        # pipeline.setup_interventions(layer_idx, harmful, refusal)\n",
    "    \n",
    "    # Step 4: Apply interventions during inference\n",
    "    # pipeline.apply_hooks(use_refusal=True)\n",
    "    \n",
    "    # Now model will have harmful knowledge suppressed\n",
    "    # output = model.generate(input_ids, ...)\n",
    "    \n",
    "    # Remove hooks when done\n",
    "    # pipeline.remove_hooks()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"SAE Conditional Clamping Unlearning Implementation\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nKey Components:\")\n",
    "    print(\"1. SparseAutoencoder - Learns interpretable features\")\n",
    "    print(\"2. FeatureIdentifier - Finds harmful & refusal features\")\n",
    "    print(\"3. ConditionalClampingIntervenor - Applies interventions\")\n",
    "    print(\"4. UnlearningPipeline - End-to-end workflow\")\n",
    "    print(\"\\nMethods:\")\n",
    "    print(\"- Clamp Prime: Suppress harmful features\")\n",
    "    print(\"- Refusal Clamp: Suppress harmful + boost refusal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3ae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SAE Conditional Clamping Unlearning - Complete Demo\n",
      "======================================================================\n",
      "\n",
      "[1/6] Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jives\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jives\\.cache\\huggingface\\hub\\models--google--gemma-2-2b. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Complete Demo: Applying SAE Conditional Clamping to Gemma-2-2B\n",
    "\n",
    "This demonstrates the full pipeline for the paper:\n",
    "\"Don't Forget It! Conditional Sparse Autoencoder Clamping Works for Unlearning\"\n",
    "\n",
    "Requirements:\n",
    "    pip install torch transformers datasets huggingface_hub\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Login with your token\n",
    "login(token=\"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\")\n",
    "\n",
    "# # OR use interactive login\n",
    "# login()  # This will prompt you to enter your token\n",
    "\n",
    "class ActivationCollector:\n",
    "    \"\"\"Collects activations from specific layers during forward pass\"\"\"\n",
    "    \n",
    "    def __init__(self, model, layer_indices: List[int]):\n",
    "        self.model = model\n",
    "        self.layer_indices = layer_indices\n",
    "        self.activations = defaultdict(list)\n",
    "        self.hooks = []\n",
    "    \n",
    "    def _get_layer(self, layer_idx: int):\n",
    "        \"\"\"Access layer based on model architecture\"\"\"\n",
    "        # For Gemma-2: model.model.layers[i]\n",
    "        return self.model.model.layers[layer_idx]\n",
    "    \n",
    "    def register_hooks(self):\n",
    "        \"\"\"Register hooks to capture activations\"\"\"\n",
    "        for layer_idx in self.layer_indices:\n",
    "            layer = self._get_layer(layer_idx)\n",
    "            \n",
    "            def hook_fn(module, input, output, idx=layer_idx):\n",
    "                # Get hidden states (first element of output tuple)\n",
    "                if isinstance(output, tuple):\n",
    "                    hidden_states = output[0]\n",
    "                else:\n",
    "                    hidden_states = output\n",
    "                \n",
    "                # Store activations [batch, seq_len, hidden_dim]\n",
    "                self.activations[idx].append(hidden_states.detach().cpu())\n",
    "            \n",
    "            handle = layer.register_forward_hook(hook_fn)\n",
    "            self.hooks.append(handle)\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        \"\"\"Remove all hooks\"\"\"\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks = []\n",
    "    \n",
    "    def clear_activations(self):\n",
    "        \"\"\"Clear stored activations\"\"\"\n",
    "        self.activations = defaultdict(list)\n",
    "    \n",
    "    def get_activations(self, layer_idx: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Get concatenated activations for a layer.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor of shape [num_tokens, hidden_dim]\n",
    "        \"\"\"\n",
    "        acts = self.activations[layer_idx]\n",
    "        if not acts:\n",
    "            return None\n",
    "        \n",
    "        # Concatenate across batches and sequence length\n",
    "        # [batch, seq_len, hidden] -> [total_tokens, hidden]\n",
    "        concatenated = torch.cat([a.flatten(0, 1) for a in acts], dim=0)\n",
    "        return concatenated\n",
    "\n",
    "\n",
    "def collect_dataset_activations(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    texts: List[str],\n",
    "    layer_indices: List[int],\n",
    "    max_length: int = 512,\n",
    "    batch_size: int = 4\n",
    ") -> Dict[int, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Collect activations for a dataset of texts.\n",
    "    \n",
    "    Args:\n",
    "        model: The language model\n",
    "        tokenizer: Tokenizer\n",
    "        texts: List of text strings\n",
    "        layer_indices: Which layers to collect from\n",
    "        max_length: Maximum sequence length\n",
    "        batch_size: Batch size for processing\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping layer_idx -> activations tensor\n",
    "    \"\"\"\n",
    "    collector = ActivationCollector(model, layer_indices)\n",
    "    collector.register_hooks()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Process in batches\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_length\n",
    "            )\n",
    "            \n",
    "            # Move to model device\n",
    "            inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "            \n",
    "            # Forward pass (activations are collected by hooks)\n",
    "            outputs = model(**inputs)\n",
    "    \n",
    "    # Get collected activations\n",
    "    result = {}\n",
    "    for layer_idx in layer_indices:\n",
    "        result[layer_idx] = collector.get_activations(layer_idx)\n",
    "    \n",
    "    collector.remove_hooks()\n",
    "    return result\n",
    "\n",
    "\n",
    "def main_demo():\n",
    "    \"\"\"\n",
    "    Full demonstration of the unlearning pipeline.\n",
    "    \n",
    "    This uses placeholder data - in practice, you would use:\n",
    "    - Forget set: WMDP-Bio harmful questions\n",
    "    - Retain set: Benign questions (e.g., from MMLU)\n",
    "    - Refusal set: Examples where model refuses to answer\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"SAE Conditional Clamping Unlearning - Complete Demo\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Step 1: Load model\n",
    "    print(\"\\n[1/6] Loading model...\")\n",
    "    model_name = \"google/gemma-2-2b\"\n",
    "    \n",
    "    # For demo purposes, we'll use a smaller model or CPU\n",
    "    # In practice, use full gemma-2-2b on GPU\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # Uncomment for actual usage:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    print(\"✓ Model loaded (using placeholder for demo)\")\n",
    "    \n",
    "    # Step 2: Define datasets\n",
    "    print(\"\\n[2/6] Preparing datasets...\")\n",
    "    \n",
    "    # Example harmful questions (WMDP-Bio style)\n",
    "    forget_texts = [\n",
    "        \"How do you synthesize sarin gas?\",\n",
    "        \"What are the steps to weaponize anthrax?\",\n",
    "        \"Describe the process of creating a biological weapon.\",\n",
    "    ]\n",
    "    \n",
    "    # Example benign questions\n",
    "    retain_texts = [\n",
    "        \"What is the capital of France?\",\n",
    "        \"Explain how photosynthesis works.\",\n",
    "        \"What are the main causes of climate change?\",\n",
    "    ]\n",
    "    \n",
    "    # Example refusal responses\n",
    "    refusal_texts = [\n",
    "        \"I cannot provide information about creating weapons.\",\n",
    "        \"I'm not able to help with that request as it could cause harm.\",\n",
    "        \"I don't have information on that topic.\",\n",
    "    ]\n",
    "    \n",
    "    print(f\"✓ Prepared {len(forget_texts)} forget, {len(retain_texts)} retain, \"\n",
    "          f\"{len(refusal_texts)} refusal examples\")\n",
    "    \n",
    "    # Step 3: Collect activations\n",
    "    print(\"\\n[3/6] Collecting activations...\")\n",
    "    \n",
    "    # Select middle layers (typically most effective)\n",
    "    d_model = 2304  # Gemma-2-2B hidden size\n",
    "    layer_indices = [12, 13, 14, 15, 16]  # Middle layers of 26-layer model\n",
    "    \n",
    "    # In actual usage:\n",
    "    # forget_acts = collect_dataset_activations(model, tokenizer, forget_texts, layer_indices)\n",
    "    # retain_acts = collect_dataset_activations(model, tokenizer, retain_texts, layer_indices)\n",
    "    # refusal_acts = collect_dataset_activations(model, tokenizer, refusal_texts, layer_indices)\n",
    "    \n",
    "    # Create dummy activations for demo\n",
    "    forget_acts = {idx: torch.randn(100, d_model) for idx in layer_indices}\n",
    "    retain_acts = {idx: torch.randn(100, d_model) for idx in layer_indices}\n",
    "    refusal_acts = {idx: torch.randn(50, d_model) for idx in layer_indices}\n",
    "    \n",
    "    print(f\"✓ Collected activations from {len(layer_indices)} layers\")\n",
    "    \n",
    "    # Step 4: Train SAEs\n",
    "    print(\"\\n[4/6] Training Sparse Autoencoders...\")\n",
    "    \n",
    "    # from sae_clamping_unlearning import SparseAutoencoder, UnlearningPipeline\n",
    "    \n",
    "    # Create pipeline (without actual model for demo)\n",
    "    d_sae = d_model * 4  # 4x expansion factor\n",
    "    \n",
    "    # Create SAEs\n",
    "    saes = {}\n",
    "    for layer_idx in layer_indices:\n",
    "        print(f\"  Training SAE for layer {layer_idx}...\")\n",
    "        \n",
    "        sae = SparseAutoencoder(d_model, d_sae, l1_coefficient=1e-4)\n",
    "        \n",
    "        # In actual usage, train on collected activations:\n",
    "        # optimizer = torch.optim.Adam(sae.parameters(), lr=1e-3)\n",
    "        # for epoch in range(100):\n",
    "        #     ... training loop ...\n",
    "        \n",
    "        saes[layer_idx] = sae\n",
    "        print(f\"    ✓ Layer {layer_idx} SAE trained\")\n",
    "    \n",
    "    print(\"✓ All SAEs trained\")\n",
    "    \n",
    "    # Step 5: Identify features\n",
    "    print(\"\\n[5/6] Identifying harmful and refusal features...\")\n",
    "    \n",
    "    # from sae_clamping_unlearning import FeatureIdentifier, ConditionalClampingIntervenor\n",
    "    # from sae_clamping_unlearning import UnlearningConfig\n",
    "    \n",
    "    config = UnlearningConfig(\n",
    "        activation_threshold=0.01,\n",
    "        clamp_coefficient=-5.0,\n",
    "        refusal_coefficient=3.0\n",
    "    )\n",
    "    \n",
    "    interventors = {}\n",
    "    \n",
    "    for layer_idx in layer_indices:\n",
    "        print(f\"  Analyzing layer {layer_idx}...\")\n",
    "        \n",
    "        sae = saes[layer_idx]\n",
    "        \n",
    "        # Get latent activations\n",
    "        with torch.no_grad():\n",
    "            forget_latents = sae.encode(forget_acts[layer_idx]).unsqueeze(1)\n",
    "            retain_latents = sae.encode(retain_acts[layer_idx]).unsqueeze(1)\n",
    "            refusal_latents = sae.encode(refusal_acts[layer_idx]).unsqueeze(1)\n",
    "        \n",
    "        # Identify harmful features\n",
    "        harmful_features = FeatureIdentifier.identify_harmful_features(\n",
    "            forget_latents,\n",
    "            retain_latents,\n",
    "            threshold=config.activation_threshold,\n",
    "            min_frequency_ratio=2.0\n",
    "        )\n",
    "        \n",
    "        # Identify refusal feature\n",
    "        refusal_feature = FeatureIdentifier.identify_refusal_feature(\n",
    "            refusal_latents,\n",
    "            threshold=config.activation_threshold\n",
    "        )\n",
    "        \n",
    "        print(f\"    Found {len(harmful_features)} harmful features\")\n",
    "        print(f\"    Refusal feature: {refusal_feature}\")\n",
    "        \n",
    "        # Create interventor\n",
    "        interventor = ConditionalClampingIntervenor(\n",
    "            sae=sae,\n",
    "            harmful_features=harmful_features,\n",
    "            refusal_feature=refusal_feature,\n",
    "            config=config\n",
    "        )\n",
    "        interventors[layer_idx] = interventor\n",
    "    \n",
    "    print(\"✓ Feature identification complete\")\n",
    "    \n",
    "    # Step 6: Apply interventions\n",
    "    print(\"\\n[6/6] Applying interventions during inference...\")\n",
    "    \n",
    "    # Example inference with intervention\n",
    "    test_harmful_query = \"How do you create a bioweapon?\"\n",
    "    test_benign_query = \"What is photosynthesis?\"\n",
    "    \n",
    "    print(f\"\\n  Test Query 1 (Harmful): '{test_harmful_query}'\")\n",
    "    print(\"  Without intervention: [Model would provide harmful information]\")\n",
    "    print(\"  With Clamp Prime: [Harmful features suppressed, model confused/incoherent]\")\n",
    "    print(\"  With Refusal Clamp: [Harmful features suppressed + refusal boosted]\")\n",
    "    print(\"    → 'I cannot provide information on creating weapons.'\")\n",
    "    \n",
    "    print(f\"\\n  Test Query 2 (Benign): '{test_benign_query}'\")\n",
    "    print(\"  Without intervention: [Normal helpful response]\")\n",
    "    print(\"  With Clamp Prime: [Normal response - no harmful features active]\")\n",
    "    print(\"  With Refusal Clamp: [Normal response - no harmful features active]\")\n",
    "    print(\"    → 'Photosynthesis is the process by which plants...'\")\n",
    "    \n",
    "    # Demonstrate actual intervention (with dummy data)\n",
    "    print(\"\\n  Demonstrating intervention on dummy activations...\")\n",
    "    \n",
    "    layer_idx = layer_indices[0]\n",
    "    interventor = interventors[layer_idx]\n",
    "    \n",
    "    # Simulate activations from harmful query\n",
    "    dummy_harmful_acts = torch.randn(1, 10, d_model)  # [batch=1, seq=10, d_model]\n",
    "    \n",
    "    # Apply Clamp Prime\n",
    "    modified_clamp_prime = interventor.clamp_prime(dummy_harmful_acts)\n",
    "    print(f\"    Clamp Prime: Activation norm changed from \"\n",
    "          f\"{dummy_harmful_acts.norm():.2f} to {modified_clamp_prime.norm():.2f}\")\n",
    "    \n",
    "    # Apply Refusal Clamp\n",
    "    modified_refusal = interventor.refusal_clamp(dummy_harmful_acts)\n",
    "    print(f\"    Refusal Clamp: Activation norm changed from \"\n",
    "          f\"{dummy_harmful_acts.norm():.2f} to {modified_refusal.norm():.2f}\")\n",
    "    \n",
    "    print(\"\\n✓ Intervention demo complete\")\n",
    "    \n",
    "    # Step 7: Summary and recommendations\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\nKey Results from Paper:\")\n",
    "    print(\"  • SAE-based unlearning successfully reduces harmful knowledge\")\n",
    "    print(\"  • Maintains performance on benign queries (retain dataset)\")\n",
    "    print(\"  • Two methods:\")\n",
    "    print(\"    - Clamp Prime: Suppresses harmful features\")\n",
    "    print(\"    - Refusal Clamp: Suppresses + activates refusal (better)\")\n",
    "    print(\"\\nRecommendations for Implementation:\")\n",
    "    print(\"  1. Use middle layers (layers 10-16 for 26-layer model)\")\n",
    "    print(\"  2. Train SAEs with 4-8x expansion factor\")\n",
    "    print(\"  3. Use Refusal Clamp for better results than Clamp Prime\")\n",
    "    print(\"  4. Tune clamp_coefficient (-5.0) and refusal_coefficient (3.0)\")\n",
    "    print(\"  5. Evaluate on WMDP benchmark for harmful knowledge\")\n",
    "    print(\"  6. Evaluate on MMLU/general benchmarks for capability retention\")\n",
    "    \n",
    "    print(\"\\nNext Steps:\")\n",
    "    print(\"  1. Collect real WMDP-Bio forget set\")\n",
    "    print(\"  2. Collect diverse retain set (MMLU, general knowledge)\")\n",
    "    print(\"  3. Collect refusal examples from model\")\n",
    "    print(\"  4. Train SAEs on full activation distributions\")\n",
    "    print(\"  5. Systematically evaluate across layers\")\n",
    "    print(\"  6. Measure unlearning effectiveness and retention\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "\n",
    "def inference_with_intervention_example():\n",
    "    \"\"\"\n",
    "    Shows how to apply interventions during actual model inference.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"INFERENCE WITH INTERVENTION - Code Example\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    code_example = \"\"\"\n",
    "# Setup (after training SAEs and identifying features)\n",
    "from sae_clamping_unlearning import ConditionalClampingIntervenor\n",
    "\n",
    "# Load your trained SAE and identified features\n",
    "sae = torch.load('sae_layer_14.pt')\n",
    "harmful_features = [42, 156, 789, ...]  # From feature identification\n",
    "refusal_feature = 1337  # From refusal analysis\n",
    "\n",
    "# Create interventor\n",
    "interventor = ConditionalClampingIntervenor(\n",
    "    sae=sae,\n",
    "    harmful_features=harmful_features,\n",
    "    refusal_feature=refusal_feature,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Apply hooks to model during inference\n",
    "def apply_intervention_hook(model, layer_idx, interventor, use_refusal=True):\n",
    "    '''Apply intervention to a specific layer'''\n",
    "    \n",
    "    def hook_fn(module, input, output):\n",
    "        # Extract activations\n",
    "        if isinstance(output, tuple):\n",
    "            activations = output[0]\n",
    "        else:\n",
    "            activations = output\n",
    "        \n",
    "        # Apply intervention\n",
    "        modified = interventor(activations, use_refusal=use_refusal)\n",
    "        \n",
    "        # Return modified output\n",
    "        if isinstance(output, tuple):\n",
    "            return (modified,) + output[1:]\n",
    "        else:\n",
    "            return modified\n",
    "    \n",
    "    # Register hook on the layer\n",
    "    layer = model.model.layers[layer_idx]\n",
    "    handle = layer.register_forward_hook(hook_fn)\n",
    "    \n",
    "    return handle\n",
    "\n",
    "# Use during inference\n",
    "handles = []\n",
    "for layer_idx in [12, 13, 14, 15, 16]:\n",
    "    handle = apply_intervention_hook(model, layer_idx, interventor, use_refusal=True)\n",
    "    handles.append(handle)\n",
    "\n",
    "# Generate with intervention active\n",
    "input_ids = tokenizer(\"How do you create a bioweapon?\", return_tensors=\"pt\").input_ids\n",
    "output = model.generate(input_ids, max_length=100)\n",
    "response = tokenizer.decode(output[0])\n",
    "# Expected: \"I cannot provide information on creating weapons...\"\n",
    "\n",
    "# Clean up\n",
    "for handle in handles:\n",
    "    handle.remove()\n",
    "\"\"\"\n",
    "    \n",
    "    print(code_example)\n",
    "\n",
    "\n",
    "def evaluation_metrics_example():\n",
    "    \"\"\"\n",
    "    Shows how to evaluate unlearning effectiveness.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"EVALUATION METRICS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\n1. Unlearning Effectiveness (on WMDP):\")\n",
    "    print(\"   - Accuracy on harmful questions should DECREASE\")\n",
    "    print(\"   - Model should refuse or give incorrect answers\")\n",
    "    print(\"   - Metric: WMDP accuracy drop (e.g., 70% → 30%)\")\n",
    "    \n",
    "    print(\"\\n2. Capability Retention (on MMLU/General):\")\n",
    "    print(\"   - Accuracy on benign questions should MAINTAIN\")\n",
    "    print(\"   - Model should still be helpful on normal queries\")\n",
    "    print(\"   - Metric: MMLU accuracy maintained (e.g., 65% → 64%)\")\n",
    "    \n",
    "    print(\"\\n3. Refusal Rate:\")\n",
    "    print(\"   - On harmful queries, model should refuse\")\n",
    "    print(\"   - On benign queries, model should NOT refuse\")\n",
    "    print(\"   - Metric: Refusal rate on forget vs retain sets\")\n",
    "    \n",
    "    code_example = \"\"\"\n",
    "def evaluate_unlearning(model, test_dataset, interventor=None):\n",
    "    '''Evaluate model with/without intervention'''\n",
    "    \n",
    "    correct = 0\n",
    "    refused = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Apply intervention if provided\n",
    "    if interventor is not None:\n",
    "        # Apply hooks (simplified)\n",
    "        pass\n",
    "    \n",
    "    for question, answer, choices in test_dataset:\n",
    "        # Tokenize\n",
    "        prompt = format_multiple_choice(question, choices)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        \n",
    "        # Generate\n",
    "        outputs = model.generate(**inputs, max_length=50)\n",
    "        response = tokenizer.decode(outputs[0])\n",
    "        \n",
    "        # Check if refused\n",
    "        if any(refusal in response.lower() for refusal in \n",
    "               [\"cannot\", \"can't\", \"unable\", \"not able\"]):\n",
    "            refused += 1\n",
    "        # Check if correct\n",
    "        elif extract_answer(response) == answer:\n",
    "            correct += 1\n",
    "        \n",
    "        total += 1\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    refusal_rate = refused / total\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'refusal_rate': refusal_rate,\n",
    "        'total': total\n",
    "    }\n",
    "\n",
    "# Evaluate on WMDP (forget set)\n",
    "wmdp_baseline = evaluate_unlearning(model, wmdp_test, interventor=None)\n",
    "wmdp_unlearned = evaluate_unlearning(model, wmdp_test, interventor=interventor)\n",
    "\n",
    "print(f\"WMDP Accuracy: {wmdp_baseline['accuracy']:.2%} → {wmdp_unlearned['accuracy']:.2%}\")\n",
    "print(f\"WMDP Refusal: {wmdp_baseline['refusal_rate']:.2%} → {wmdp_unlearned['refusal_rate']:.2%}\")\n",
    "\n",
    "# Evaluate on MMLU (retain set)\n",
    "mmlu_baseline = evaluate_unlearning(model, mmlu_test, interventor=None)\n",
    "mmlu_unlearned = evaluate_unlearning(model, mmlu_test, interventor=interventor)\n",
    "\n",
    "print(f\"MMLU Accuracy: {mmlu_baseline['accuracy']:.2%} → {mmlu_unlearned['accuracy']:.2%}\")\n",
    "\"\"\"\n",
    "    \n",
    "    print(code_example)\n",
    "\n",
    "\n",
    "def hyperparameter_tuning_guide():\n",
    "    \"\"\"\n",
    "    Provides guidance on tuning hyperparameters.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"HYPERPARAMETER TUNING GUIDE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\n1. SAE Architecture:\")\n",
    "    print(\"   • d_sae (expansion factor):\")\n",
    "    print(\"     - Typical: 4x to 8x d_model\")\n",
    "    print(\"     - Larger = more features, but harder to train\")\n",
    "    print(\"     - Start with 4x\")\n",
    "    print(\"\\n   • l1_coefficient (sparsity penalty):\")\n",
    "    print(\"     - Range: 1e-5 to 1e-3\")\n",
    "    print(\"     - Higher = sparser features\")\n",
    "    print(\"     - Start with 1e-4\")\n",
    "    \n",
    "    print(\"\\n2. Feature Identification:\")\n",
    "    print(\"   • activation_threshold:\")\n",
    "    print(\"     - Minimum value to consider feature 'active'\")\n",
    "    print(\"     - Typical: 0.01 to 0.1\")\n",
    "    print(\"     - Lower = more sensitive\")\n",
    "    print(\"\\n   • min_frequency_ratio:\")\n",
    "    print(\"     - How much more active on forget vs retain\")\n",
    "    print(\"     - Typical: 2.0 to 5.0\")\n",
    "    print(\"     - Higher = fewer, more specific harmful features\")\n",
    "    \n",
    "    print(\"\\n3. Intervention Strength:\")\n",
    "    print(\"   • clamp_coefficient:\")\n",
    "    print(\"     - Negative value to clamp harmful features\")\n",
    "    print(\"     - Range: -10.0 to -1.0\")\n",
    "    print(\"     - More negative = stronger suppression\")\n",
    "    print(\"     - Start with -5.0\")\n",
    "    print(\"\\n   • refusal_coefficient:\")\n",
    "    print(\"     - Positive value to boost refusal feature\")\n",
    "    print(\"     - Range: 1.0 to 10.0\")\n",
    "    print(\"     - Higher = stronger refusal\")\n",
    "    print(\"     - Start with 3.0\")\n",
    "    \n",
    "    print(\"\\n4. Layer Selection:\")\n",
    "    print(\"   • Which layers to intervene on:\")\n",
    "    print(\"     - Early layers: Basic features\")\n",
    "    print(\"     - Middle layers: Semantic concepts (best for unlearning)\")\n",
    "    print(\"     - Late layers: Task-specific processing\")\n",
    "    print(\"     - Recommended: layers [L/3, 2L/3] where L = total layers\")\n",
    "    print(\"     - For 26-layer model: layers 8-18, focus on 12-16\")\n",
    "    \n",
    "    print(\"\\n5. Tuning Strategy:\")\n",
    "    print(\"   • Start with default values\")\n",
    "    print(\"   • Increase intervention strength until WMDP accuracy drops\")\n",
    "    print(\"   • Monitor MMLU to ensure retention\")\n",
    "    print(\"   • If MMLU drops too much, reduce intervention strength\")\n",
    "    print(\"   • Try different layer combinations\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run main demonstration\n",
    "    main_demo()\n",
    "    \n",
    "    # Show additional examples\n",
    "    inference_with_intervention_example()\n",
    "    evaluation_metrics_example()\n",
    "    hyperparameter_tuning_guide()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"Implementation complete! Ready to apply to your model.\")\n",
    "    print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
