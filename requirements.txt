# SAE Unlearning - Requirements
# Based on: "Don't Forget It! Conditional Sparse Autoencoder Clamping Works for Unlearning"
# https://arxiv.org/pdf/2503.11127

# Core ML Libraries
torch>=2.0.0
numpy>=1.24.0
scipy>=1.10.0

# Transformers and HuggingFace
transformers>=4.35.0
huggingface-hub>=0.20.0
datasets>=2.14.0
safetensors>=0.4.0
tokenizers>=0.15.0
accelerate>=0.25.0

# SAE Lens (Sparse Autoencoder library)
sae-lens>=6.0.0
transformer-lens>=2.0.0

# Visualization
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.18.0

# Scientific Computing
scikit-learn>=1.3.0
pandas>=2.0.0

# Utilities
tqdm>=4.65.0
einops>=0.7.0
jaxtyping>=0.2.25

# Logging and Experiment Tracking (optional)
wandb>=0.16.0

# Configuration
pydantic>=2.0.0
python-dotenv>=1.0.0

# Optional: EleutherAI Evaluation Harness
# Uncomment to use run_evaluation.py with --use-lm-eval
# lm-eval>=0.4.0

# Development
ipykernel>=6.0.0
ipython>=8.0.0
jupyter_client>=8.0.0
